from scholarly import scholarly
import os
import sqlite3
import logging
import requests
import aiohttp
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, KeyboardButton, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes


logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s', level=logging.INFO)
logger = logging.getLogger(__name__)


TOKEN = os.getenv('7821187888:AAGE4gJs0q5S2-Cbxsz67xU4yMoiY-2aOu4')


CROSSREF_API_URL = 'https://api.crossref.org/works/'
SEMANTIC_SCHOLAR_API_URL = 'https://api.semanticscholar.org/graph/v1/paper/search'
SCIHUB_URL = 'https://sci-hub.se/'


conn = sqlite3.connect('users.db', check_same_thread=False)
cursor = conn.cursor()


cursor.execute('''CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, username TEXT, keywords TEXT, state TEXT)''')
cursor.execute('''CREATE TABLE IF NOT EXISTS stats (searches_successful INTEGER, searches_failed INTEGER)''')
cursor.execute('''CREATE TABLE IF NOT EXISTS auto_article (chat_id INTEGER ,keywords TEXT''')
conn.commit()


def update_user_state(user_id, state):
    cursor.execute('UPDATE users SET state = ? WHERE id = ?', (state, user_id))
    conn.commit()


def get_user_state(user_id):
    cursor.execute('SELECT state FROM users WHERE id = ?', (user_id,))
    result = cursor.fetchone()
    return result[0] if result else None


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.message.from_user
    cursor.execute('INSERT OR IGNORE INTO users (id, username, keywords, state) VALUES (?, ?, ?, ?)', (user.id, user.username, None, None))
    conn.commit()

    keyboards = [
        [KeyboardButton('Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø§ DOI'), KeyboardButton('Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø§ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ')],
        [KeyboardButton(' Ø§Ø±Ø³Ø§Ù„ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ù‚Ø§Ù„Ø§Øª ')],
    ]
    reply_markup = ReplyKeyboardMarkup(keyboards, resize_keyboard=True)
    await update.message.reply_text('Ø³Ù„Ø§Ù… Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù…Ù‚Ø§Ù„Ù‡ ÛŒØ§Ø¨ Ø®ÙˆØ´ Ø§ÙˆÙ…Ø¯ÛŒÙ†', reply_markup=reply_markup)







async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_id = update.message.from_user.id
    text = update.message.text
    user_message = update.message.text

    if text == 'Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø§ DOI':
        update_user_state(user_id, 'awaiting_doi')
        await update.message.reply_text('DOI Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:')

    elif text == 'Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø§ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ':
        update_user_state(user_id, 'awaiting_keywords')
        await update.message.reply_text('Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¯Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯):')

    elif text == ' Ø§Ø±Ø³Ø§Ù„ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ù‚Ø§Ù„Ø§Øª ':
        await manage_auto_article_sending(update,context)

    else:
        state = get_user_state(user_id)
        if state == 'awaiting_doi':
            if "https://doi.org/" in user_message:
                doi = user_message.split("https://doi.org/")[-1].strip()
            else:
                doi = user_message
            result = await search_in_multiple_sources(doi)
            update_user_state(user_id, None)
            await update.message.reply_text(result)

        elif state == 'awaiting_keywords':
            keywords = user_message.replace(',', ' ').split()
            result = await search_in_multiple_sources(' AND '.join(keywords))
            update_user_state(user_id, None)
            await update.message.reply_text(result)



def save_keyword_for_user(chat_id,keywords):
    
    conn = sqlite3.connect('users.db', check_same_thread=False)
    cursor = conn.cursor()
    cursor.execute('INSERT OR REPLACE INTO auto_article (chat_id,keywords) VSLUES ( ?, ?)',(chat_id,keywords))
    conn.commit()
    conn.close()


def remove_subscriber(chat_id):
    conn = sqlite3.connect('subscribers.db')
    cursor = conn.cursor()

    cursor.execute(f'DELETE FROM  WHERE chat_id = ?', (chat_id,))
    conn.commit()
    conn.close()






async def manage_auto_article_sending(update:Update,context:ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    state = get_user_state(user_id)

    if state is None:
        update_user_state(user_id,'awaiting_keywords')
        await update.message.reply_text('Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ ( Ú©Ù„Ù…Ø§Øª Ø±Ø§ Ø¨Ø§ Ú©Ø§Ù…Ø§ , Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯)')
    else :
        await update.message.reply_text('Ø´Ù…Ø§ Ù‚Ø¨Ù„Ø§ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¹Ø¶Ùˆ Ø´Ø¯ÛŒØ¯!')




async def check_new_article():
    while True:
        cursor.execute('SELECT user_id , keywords FROM auto_article')
        users =cursor.fetchall()

        for user_id , keywords in users:
            new_article = await search_in_multiple_sources(keywords)

            if new_article:
                await send_articles_to_user(user_id,new_article)

        await asyncio.sleep(24 * 3600)






async def send_articles_to_user(user_id,articles):
    cursor.execute('SELECT username FROM users WHERE id = ?'(user_id,))
    username = cursor.fetchone()[0]

    if username:






async def search_in_multiple_sources(keywords_or_doi: str) -> str:
    if keywords_or_doi.startswith('10.'):
        result = await fetch_article_by_doi(keywords_or_doi)
        if result:
            cursor.execute('UPDATE stats SET searches_successful = searches_successful + 1')
            conn.commit()
            return result


        result = fetch_scihub_article(keywords_or_doi)
        if result:
            cursor.execute('UPDATE stats SET searches_successful = searches_successful + 1')
            conn.commit()
            return result
    else:
        keywords = ' AND '.join(keywords_or_doi.split(','))
        result = await search_articles_by_keywords_scholar(keywords)
        if result:
            cursor.execute('UPDATE stats SET searches_successful = searches_successful + 1')
            conn.commit()
            return result

        result = await search_articles_by_keywords_google(keywords)
        if result:
            cursor.execute('UPDATE stats SET searches_successful = searches_successful + 1')
            conn.commit()
            return result

        result = await search_arxiv(keywords)
        if result:
            cursor.execute('UPDATE stats SET searches_successful = searches_successful + 1')
            conn.commit()
            return result

        result = await search_pubmed(keywords)
        if result:
            cursor.execute('UPDATE stats SET searches_successful = searches_successful + 1')
            conn.commit()
            return result

    cursor.execute('UPDATE stats SET searches_failed = searches_failed + 1')
    conn.commit()
    return "Ù‡ÛŒÚ† Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."





async def fetch_article_by_doi(doi: str) -> str:
    async with aiohttp.ClientSession() as session:
        async with session.get(f"{CROSSREF_API_URL}{doi}") as response:
            if response.status == 200:
                data = await response.json()
                title = data['message'].get('title', ['Ø¹Ù†ÙˆØ§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯'])[0]
                authors = data['message'].get('author', [])

                author_names = [f"{author.get('given', 'Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡')} {author.get('family', '')}".strip() for author in authors]
                authors_str = ', '.join(author_names) if author_names else 'Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡'

                # Ø¯Ú©Ù…Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF
                pdf_link = data['message'].get('URL', 'Ù„ÛŒÙ†Ú©ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª')
                return f"ğŸ“š Ø¹Ù†ÙˆØ§Ù†: {title}\nğŸ‘¨â€ğŸ”¬ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: {authors_str}\nğŸ”— DOI: {doi}\nğŸ”— URL: {pdf_link}"

            return "Ù…ØªØ§Ø³ÙÙ…ØŒ Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ø§ÛŒÙ† DOI Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."


def fetch_scihub_article(doi: str) -> str:
    url = f"{SCIHUB_URL}{doi}"
    return f"ğŸ“° Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ Ø¨Ø§ DOI: {doi} Ø¯Ø± Sci-Hub Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª. Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯: {url}"


async def search_articles_by_keywords_scholar(keywords: str) -> str:
    async with aiohttp.ClientSession() as session:
        async with session.get(f"{SEMANTIC_SCHOLAR_API_URL}?query={keywords}&limit=3") as response:
            if response.status == 200:
                data = await response.json()
                articles = ""
                for paper in data['data']:
                    title = paper['title']
                    authors = ', '.join(paper['authors'])
                    url = paper['url']
                    articles += f"ğŸ“š Ø¹Ù†ÙˆØ§Ù†: {title}\nğŸ‘¨â€ğŸ”¬ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: {authors}\nğŸ”— URL: {url}\n\n"
                return articles if articles else "Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."


async def search_articles_by_keywords_google(keywords: str) -> str:
    search_query = scholarly.search_pubs(keywords)
    articles = ""
    for result in search_query:
        title = result['bib']['title']
        authors = result['bib'].get('author', 'Unknown')
        url = result.get('pub_url', 'No URL available')
        articles += f"ğŸ“š Ø¹Ù†ÙˆØ§Ù†: {title}\nğŸ‘¨â€ğŸ”¬ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: {authors}\nğŸ”— URL: {url}\n\n"
        return articles if articles else "Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."


async def search_arxiv(keywords: str) -> str:
    url = f"http://export.arxiv.org/api/query?search_query=all:{keywords}&start=0&max_results=3"


    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            if response.status == 200:
                entries = (await response.text()).split('<entry>')[1:]
                articles = ""
                for entry in entries:
                    title = entry.split('<title>')[1].split('</title>')[0]
                    authors = entry.split('<name>')[1].split('</name>')[0]
                    link = entry.split('<id>')[1].split('</id>')[0]
                    articles += f"ğŸ“š Ø¹Ù†ÙˆØ§Ù†: {title.strip()}\nğŸ‘¨â€ğŸ”¬ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: {authors.strip()}\nğŸ”— URL: {link}\n\n"
                return articles if articles else "Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."


async def search_pubmed(keywords: str) -> str:
    url = f"https://api.ncbi.nlm.nih.gov/lit/ctxp/v1/pubmed/?format=ris&term={keywords}"
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            if response.status == 200:
                data = await response.text()
                articles = ""
                for entry in data.split('\n\n'):
                    if 'TI  -' in entry and 'AU  -' in entry:
                        title = entry.split('TI  - ')[1].split('\n')[0]
                        author = entry.split('AU  - ')[1].split('\n')[0]
                        articles += f"ğŸ“š Ø¹Ù†ÙˆØ§Ù†: {title.strip()}\nğŸ‘¨â€ğŸ”¬ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: {author.strip()}\n\n"
                return articles if articles else "Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."


async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    cursor.execute('SELECT * FROM stats')
    stats_data = cursor.fetchone()
    if stats_data:
        searches_successful, searches_failed = stats_data
        await update.message.reply_text(f"ğŸ“Š Ø¢Ù…Ø§Ø± Ø¬Ø³ØªØ¬Ùˆ:\nâœ… Ø¬Ø³ØªØ¬ÙˆÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚: {searches_successful}\nâŒ Ø¬Ø³ØªØ¬ÙˆÙ‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚: {searches_failed}")
    else:
        await update.message.reply_text("Ø¢Ù…Ø§Ø± Ù‡Ù†ÙˆØ² Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")


def main():
    app = Application.builder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(CommandHandler("stats", stats))

    cursor.execute('INSERT OR IGNORE INTO stats (searches_successful, searches_failed) VALUES (0, 0)')
    conn.commit()

    app.run_polling()

if __name__ == '__main__':
    main()